Testing model_name: opt_125m, task_id: causalLM
PATH CHECK: ['/home/yl_code/meta_zo2/zo2/test/mezo_sgd/hf_opt', '/home/vipuser/miniconda3/envs/zo2/lib/python311.zip', '/home/vipuser/miniconda3/envs/zo2/lib/python3.11', '/home/vipuser/miniconda3/envs/zo2/lib/python3.11/lib-dynload', '/home/vipuser/miniconda3/envs/zo2/lib/python3.11/site-packages', '/home/yl_code/meta_zo2/zo2']
disk
å¼€å§‹cpuå†…å­˜ï¼š427.9453125
Transformer blocks [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] will be offloaded to disk
model size: 0.15 B
  0%|          | 0/3 [00:00<?, ?it/s]/home/yl_code/meta_zo2/zo2/zo2/optimizer/mezo_sgd/zo2.py:469: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location="cpu")
                                       0%|          | 0/3 [00:00<?, ?it/s]                                       0%|          | 0/3 [00:00<?, ?it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.08it/s]                                              33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:01,  1.08it/s]                                              33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:01,  1.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.41it/s]                                              67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:02<00:00,  1.41it/s]                                              67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:02<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.59it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.48it/s]
æµ‹è¯•ç‚¹1: 158357504
æµ‹è¯•ç‚¹2: 397432832
æµ‹è¯•ç‚¹4: 397432832
1æµ‹è¯•ç‚¹çš„7: 397432832
1çš„æµ‹è¯•ç‚¹8: 635094528
2æµ‹è¯•ç‚¹çš„7: 635094528
2çš„æµ‹è¯•ç‚¹8: 649270272
3æµ‹è¯•ç‚¹çš„7: 649270272
3çš„æµ‹è¯•ç‚¹8: 664363520
4æµ‹è¯•ç‚¹çš„7: 664363520
4çš„æµ‹è¯•ç‚¹8: 679456768
5æµ‹è¯•ç‚¹çš„7: 679456768
5çš„æµ‹è¯•ç‚¹8: 694550016
6æµ‹è¯•ç‚¹çš„7: 694550016
6çš„æµ‹è¯•ç‚¹8: 709643264
7æµ‹è¯•ç‚¹çš„7: 709643264
7çš„æµ‹è¯•ç‚¹8: 723819008
8æµ‹è¯•ç‚¹çš„7: 723819008
8çš„æµ‹è¯•ç‚¹8: 738912256
9æµ‹è¯•ç‚¹çš„7: 738912256
9çš„æµ‹è¯•ç‚¹8: 753088000
10æµ‹è¯•ç‚¹çš„7: 753088000
10çš„æµ‹è¯•ç‚¹8: 768181248
11æµ‹è¯•ç‚¹çš„7: 768181248
11çš„æµ‹è¯•ç‚¹8: 783274496
æµ‹è¯•ç‚¹5: 783274496
æµ‹è¯•ç‚¹6: 798367744
æµ‹è¯•ç‚¹3: 798367744
PyTorch Process Peak GPU Memory after iteration 1: 949.12 MB
Peak CPU Memory after iteration 1: 1016.08 MB
æµ‹è¯•ç‚¹1: 995229696
æµ‹è¯•ç‚¹2: 995229696
æµ‹è¯•ç‚¹4: 995229696
1æµ‹è¯•ç‚¹çš„7: 995229696
1çš„æµ‹è¯•ç‚¹8: 995229696
2æµ‹è¯•ç‚¹çš„7: 995229696
2çš„æµ‹è¯•ç‚¹8: 995229696
3æµ‹è¯•ç‚¹çš„7: 995229696
3çš„æµ‹è¯•ç‚¹8: 995229696
4æµ‹è¯•ç‚¹çš„7: 995229696
4çš„æµ‹è¯•ç‚¹8: 995229696
5æµ‹è¯•ç‚¹çš„7: 995229696
5çš„æµ‹è¯•ç‚¹8: 995229696
6æµ‹è¯•ç‚¹çš„7: 995229696
6çš„æµ‹è¯•ç‚¹8: 995229696
7æµ‹è¯•ç‚¹çš„7: 995229696
7çš„æµ‹è¯•ç‚¹8: 995229696
8æµ‹è¯•ç‚¹çš„7: 995229696
8çš„æµ‹è¯•ç‚¹8: 995229696
9æµ‹è¯•ç‚¹çš„7: 995229696
9çš„æµ‹è¯•ç‚¹8: 995229696
10æµ‹è¯•ç‚¹çš„7: 995229696
10çš„æµ‹è¯•ç‚¹8: 995229696
11æµ‹è¯•ç‚¹çš„7: 995229696
11çš„æµ‹è¯•ç‚¹8: 995229696
æµ‹è¯•ç‚¹5: 995229696
æµ‹è¯•ç‚¹6: 995229696
æµ‹è¯•ç‚¹3: 995229696
PyTorch Process Peak GPU Memory after iteration 2: 949.12 MB
Peak CPU Memory after iteration 2: 1021.05 MB
æµ‹è¯•ç‚¹1: 995229696
æµ‹è¯•ç‚¹2: 995229696
æµ‹è¯•ç‚¹4: 995229696
1æµ‹è¯•ç‚¹çš„7: 995229696
1çš„æµ‹è¯•ç‚¹8: 995229696
2æµ‹è¯•ç‚¹çš„7: 995229696
2çš„æµ‹è¯•ç‚¹8: 995229696
3æµ‹è¯•ç‚¹çš„7: 995229696
3çš„æµ‹è¯•ç‚¹8: 995229696
4æµ‹è¯•ç‚¹çš„7: 995229696
4çš„æµ‹è¯•ç‚¹8: 995229696
5æµ‹è¯•ç‚¹çš„7: 995229696
5çš„æµ‹è¯•ç‚¹8: 995229696
6æµ‹è¯•ç‚¹çš„7: 995229696
6çš„æµ‹è¯•ç‚¹8: 995229696
7æµ‹è¯•ç‚¹çš„7: 995229696
7çš„æµ‹è¯•ç‚¹8: 995229696
8æµ‹è¯•ç‚¹çš„7: 995229696
8çš„æµ‹è¯•ç‚¹8: 995229696
9æµ‹è¯•ç‚¹çš„7: 995229696
9çš„æµ‹è¯•ç‚¹8: 995229696
10æµ‹è¯•ç‚¹çš„7: 995229696
10çš„æµ‹è¯•ç‚¹8: 995229696
11æµ‹è¯•ç‚¹çš„7: 995229696
11çš„æµ‹è¯•ç‚¹8: 995229696
æµ‹è¯•ç‚¹5: 995229696
æµ‹è¯•ç‚¹6: 995229696
æµ‹è¯•ç‚¹3: 995229696
PyTorch Process Peak GPU Memory after iteration 3: 949.12 MB
Peak CPU Memory after iteration 3: 1022.19 MB
Recording Peak GPU and CPU Memory usage...
Model: opt_125m, Task: causalLM
ZO2 peak GPU memory: [0;32miteration MB[0m
ZO2 peak CPU memory: [0;32m1022.19 MB[0m
